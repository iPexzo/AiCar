import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import analyzeRouter from "./apis/routes/analyze";
import uploadRouter from "./apis/routes/upload";
import authRouter from "./apis/routes/auth";
import carAnalysisRouter from "./apis/routes/carAnalysis";
import carQueryRouter from "./apis/routes/carQuery";
import { body, validationResult } from "express-validator";
import OpenAI from "openai";
import { spawn } from "child_process";
import { promisify } from "util";
import { exec } from "child_process";
import net from "net";

// Load environment variables
dotenv.config();
console.log("Loaded OpenAI Key:", process.env.OPENAI_API_KEY?.slice(0, 12));

const app = express();
const PORT = process.env.PORT || 8001;
const HOST = process.env.HOST || "0.0.0.0";

// Enhanced CORS configuration for simulators
const corsOptions = {
  origin: [
    "http://localhost:3000",
    "http://localhost:8081",
    "http://localhost:8082",
    "http://localhost:19006",
    "exp://localhost:19000",
    "exp://192.168.8.149:19000",
    "http://10.0.2.2:8001",
    "http://10.0.2.2:3000",
    "http://10.0.2.2:8081",
    "http://10.0.2.2:8082",
    "http://192.168.8.149:8001",
    "http://192.168.8.149:3000",
    "http://192.168.8.149:8081",
    "http://192.168.8.149:8082",
  ],
  credentials: true,
  methods: ["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"],
  allowedHeaders: ["Content-Type", "Authorization", "X-Requested-With"],
};

// OpenAI setup
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Check if OpenAI API key is configured
if (!process.env.OPENAI_API_KEY) {
  console.warn("‚ö†Ô∏è  WARNING: OPENAI_API_KEY is not configured!");
  console.warn("   The AI analysis will use a fallback template response.");
  console.warn(
    "   To enable real AI analysis, add your OpenAI API key to .env file"
  );
}

console.log("=== Car AI Backend Server Starting ===");
console.log("=== CORS enabled for all origins ===");

// Enable CORS with enhanced configuration for simulators
app.use(cors(corsOptions));

app.use(express.json({ limit: "10mb" }));
app.use(express.urlencoded({ extended: true }));

// Debug middleware to log all requests
app.use((req, res, next) => {
  console.log(`[DEBUG] ${req.method} ${req.originalUrl} - IP: ${req.ip}`);
  next();
});

// Health check endpoint
app.get("/health", (req, res) => {
  res.json({
    status: "OK",
    message: "Car AI Backend is running",
    timestamp: new Date().toISOString(),
  });
});

// API routes
app.use("/api/analyze", analyzeRouter);
app.use("/api/upload", uploadRouter);
app.use("/api/auth", authRouter);
app.use("/api/car-analysis", carAnalysisRouter);
app.use("/api/car-query", carQueryRouter);

// Port checking and process management
async function checkAndKillPort(port: number): Promise<void> {
  return new Promise((resolve) => {
    console.log(`üîç Checking if port ${port} is available...`);

    // Use kill-port package for more reliable port management
    const killPort = spawn("npx", ["kill-port", port.toString()], {
      shell: true,
      stdio: "pipe",
    });

    let output = "";
    let errorOutput = "";

    killPort.stdout.on("data", (data) => {
      output += data.toString();
    });

    killPort.stderr.on("data", (data) => {
      errorOutput += data.toString();
    });

    killPort.on("close", (code) => {
      if (code === 0) {
        console.log(`‚úÖ Port ${port} is now available`);
        // Wait a bit for the port to be fully released
        setTimeout(() => resolve(), 1000);
      } else {
        // Even if kill-port fails, we'll try to start the server anyway
        console.log(`‚ö†Ô∏è  Port ${port} check completed (code: ${code})`);
        if (output) console.log(`Output: ${output.trim()}`);
        if (errorOutput) console.log(`Error: ${errorOutput.trim()}`);
        setTimeout(() => resolve(), 1000);
      }
    });

    killPort.on("error", (error) => {
      console.log(`‚ö†Ô∏è  Error checking port: ${error.message}`);
      setTimeout(() => resolve(), 1000);
    });
  });
}

// Utility to find the first available port starting from basePort
async function findAvailablePort(
  basePort: number,
  maxAttempts = 10
): Promise<number> {
  for (let i = 0; i < maxAttempts; i++) {
    const port = basePort + i;
    const isFree = await new Promise<boolean>((resolve) => {
      const tester = net
        .createServer()
        .once("error", (err: any) => {
          if (err.code === "EADDRINUSE") resolve(false);
          else resolve(false);
        })
        .once("listening", () => {
          tester.close();
          resolve(true);
        })
        .listen(port, HOST);
    });
    if (isFree) return port;
  }
  throw new Error(
    `No available port found from ${basePort} to ${basePort + maxAttempts - 1}`
  );
}

// Refactored handleAIDiagnosis for 3-step flow
async function handleAIDiagnosis(req: express.Request, res: express.Response) {
  const {
    carType,
    carModel,
    mileage,
    lastServiceType,
    problemDescription,
    previousQuestions = [],
    previousAnswers = [],
    chatHistory = [],
    step,
  } = req.body;

  // Step auto-detection if not provided
  let currentStep = step;
  if (!currentStep) {
    if (previousQuestions.length === 0 && previousAnswers.length === 0) {
      currentStep = "initial";
    } else if (previousQuestions.length < 3) {
      currentStep = "questions";
    } else {
      currentStep = "final";
    }
  }

  // Helper: Build chat history section
  function buildHistorySection() {
    let historySection = "";
    if (chatHistory.length > 0) {
      historySection = "\n\nÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©:";
      chatHistory.forEach((msg: string, i: number) => {
        historySection += `\n${msg}`;
      });
    } else if (previousQuestions.length > 0) {
      historySection = "\n\nÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©:";
      previousQuestions.forEach((q: string, i: number) => {
        const answer = previousAnswers[i] || "(ÿ®ÿØŸàŸÜ ÿ•ÿ¨ÿßÿ®ÿ©)";
        historySection += `\nÿ≥ÿ§ÿßŸÑ: ${q}\nÿ•ÿ¨ÿßÿ®ÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: ${answer}`;
      });
    }
    return historySection;
  }

  // Step 1: Initial analysis + Generate initial smart questions
  if (currentStep === "initial") {
    const historySection = buildHistorySection();
    const preliminaryPrompt = `\nÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ™ÿßŸÑŸä Ÿàÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿå ŸÇÿØŸÖ ŸÜÿ∏ÿ±ÿ© ÿπÿßŸÖÿ© ÿ£ŸàŸÑŸäÿ© ŸÅŸÇÿ∑ ÿπŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©.\n\nŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©:\n- ÿßŸÑŸÜŸàÿπ: ${carType}\n- ÿßŸÑŸÖŸàÿØŸäŸÑ: ${carModel}\n- ÿßŸÑŸÖŸÖÿ¥Ÿâ: ${mileage} ŸÉŸÖ\n${
      lastServiceType ? `- ÿ¢ÿÆÿ± ÿµŸäÿßŸÜÿ©: ${lastServiceType}` : ""
    }\n${historySection}\n\nŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©:\n${problemDescription}\n\nŸÖÿ∑ŸÑŸàÿ® ŸÖŸÜŸÉ:\n1. ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿ£ŸàŸÑŸä ÿπÿßŸÖ ŸÑŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖÿ™ŸàŸÅÿ±ÿ©\n2. ŸÑÿß ÿ™ÿ∞ŸÉÿ± ÿ£ÿ≥ŸÖÿßÿ° ŸÇÿ∑ÿπ ÿ∫Ÿäÿßÿ± ŸÖÿ≠ÿØÿØÿ©\n3. ŸÑÿß ÿ™ÿ∞ŸÉÿ± ÿ£ÿ≥ÿπÿßÿ± ÿ£Ÿà ÿ™ŸÉÿßŸÑŸäŸÅ\n4. ŸÑÿß ÿ™ŸÇÿØŸÖ ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿ•ÿµŸÑÿßÿ≠ ŸÖŸÅÿµŸÑÿ©\n5. ŸÑÿß ÿ™ŸÇÿ™ÿ±ÿ≠ ŸÖÿ±ÿßŸÉÿ≤ ÿµŸäÿßŸÜÿ© ŸÖÿ≠ÿØÿØÿ©\n6. ÿ±ŸÉÿ≤ ŸÅŸÇÿ∑ ÿπŸÑŸâ ŸÅŸáŸÖ Ÿàÿ™ÿµŸÜŸäŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ®ÿ¥ŸÉŸÑ ÿπÿßŸÖ\n7. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\n\nŸáÿ∞ÿß ÿ™ÿ≠ŸÑŸäŸÑ ÿ£ŸàŸÑŸä ŸÅŸÇÿ∑. ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ™ÿ≠ŸÑŸäŸÑ ŸÖŸÅÿµŸÑ ŸÖÿπ ÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑŸÇÿ∑ÿπ ŸàÿßŸÑÿ£ÿ≥ÿπÿßÿ±ÿå ÿ≥Ÿäÿ™ŸÖ ÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ•ÿ∂ÿßŸÅŸäÿ©.`;

    try {
      // Get preliminary analysis
      const completion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑÿßÿ™ ÿ£ŸàŸÑŸäÿ© ÿπÿßŸÖÿ©.",
          },
          { role: "user", content: preliminaryPrompt },
        ],
        max_tokens: 600,
        temperature: 0.7,
      });
      const result = completion.choices[0]?.message?.content || "";

      // Generate initial smart questions
      const smartQuestionsPrompt = `ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ™ÿßŸÑŸäÿå ÿßÿ∑ÿ±ÿ≠ 3 ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ.\n\nŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©:\n- ÿßŸÑŸÜŸàÿπ: ${carType}\n- ÿßŸÑŸÖŸàÿØŸäŸÑ: ${carModel}\n- ÿßŸÑŸÖŸÖÿ¥Ÿâ: ${mileage} ŸÉŸÖ\n${
        lastServiceType ? `- ÿ¢ÿÆÿ± ÿµŸäÿßŸÜÿ©: ${lastServiceType}` : ""
      }\n\nŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©:\n${problemDescription}\n\nŸÖÿπÿ±ŸÅ ÿßŸÑÿ¨ŸÑÿ≥ÿ©: ${
        Date.now().toString() + Math.random().toString(36).substr(2, 9)
      }\nÿßŸÑŸàŸÇÿ™: ${new Date().toISOString()}\n\nŸÖÿ∑ŸÑŸàÿ®:\n1. ÿßÿ∑ÿ±ÿ≠ 3 ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©\n2. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\n3. ÿßŸÉÿ™ÿ® ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ŸÅŸÇÿ∑ÿå ÿ®ÿØŸàŸÜ ÿ£Ÿä ÿ¥ÿ±ÿ≠ ÿ•ÿ∂ÿßŸÅŸä\n4. ÿßÿ®ÿØÿ£ ŸÉŸÑ ÿ≥ÿ§ÿßŸÑ ÿ®ÿ±ŸÇŸÖ (1. 2. 3.)\n5. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ŸÖÿÆÿµÿµÿ© ŸÑŸÑŸÖÿ¥ŸÉŸÑÿ© ŸàÿßŸÑÿ≥ŸäÿßŸÇ\n6. ÿ±ŸÉÿ≤ ÿπŸÑŸâ ÿ¨ŸàÿßŸÜÿ® ŸÖÿÆÿ™ŸÑŸÅÿ© ŸÖŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© (ÿ£ÿπÿ±ÿßÿ∂ÿå ÿ™ŸàŸÇŸäÿ™ÿå ÿ∏ÿ±ŸàŸÅÿå ÿ•ŸÑÿÆ)\n7. ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ\n\nŸÖÿ´ÿßŸÑ ÿπŸÑŸâ ÿßŸÑÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®:\n1. ŸáŸÑ ŸÑÿßÿ≠ÿ∏ÿ™ ÿ£Ÿä ÿ™ÿ∫ŸäŸäÿ± ŸÅŸä ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑŸàŸÇŸàÿØÿü\n2. ŸáŸÑ ÿ™ÿ∏Ÿáÿ± ÿ£Ÿä ÿ£ÿ∂Ÿàÿßÿ° ÿ™ÿ≠ÿ∞Ÿäÿ±Ÿäÿ© ÿπŸÑŸâ ŸÑŸàÿ≠ÿ© ÿßŸÑÿπÿØÿßÿØÿßÿ™ÿü\n3. ŸáŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ™ÿ∏Ÿáÿ± ŸÅŸä ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∏ÿ±ŸàŸÅ ÿßŸÑÿ¨ŸàŸäÿ©ÿü`;

      const questionsCompletion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿØŸäŸÜÿßŸÖŸäŸÉŸäÿ© ŸàŸÖÿÆÿµÿµÿ© ŸÑŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿØÿØ.",
          },
          { role: "user", content: smartQuestionsPrompt },
        ],
        max_tokens: 400,
        temperature: 0.8,
      });

      const questionsText =
        questionsCompletion.choices[0]?.message?.content?.trim() || "";

      // Parse up to 3 questions from the response
      const questionLines = questionsText
        .split("\n")
        .filter((line) => line.trim().match(/^\d+\./));

      const followUpQuestions = questionLines
        .slice(0, 3)
        .map((line: string, index: number) => {
          const question = line.replace(/^\d+\.\s*/, "").trim();
          return {
            id: (index + 1).toString(),
            question: question,
            type: "text",
            timestamp: new Date().toISOString(),
          };
        });

      return res.json({
        success: true,
        result: result.trim(),
        followUpQuestions,
        timestamp: new Date().toISOString(),
        note: "Preliminary analysis completed with smart questions",
      });
    } catch (err) {
      return res.status(500).json({
        success: false,
        message: "AI analysis failed",
        error: err instanceof Error ? err.message : String(err),
      });
    }
  }

  // Step 2: Generate 3 dynamic smart questions
  if (currentStep === "questions") {
    const historySection = buildHistorySection();
    const smartQuestionsPrompt = `ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿå ÿßÿ∑ÿ±ÿ≠ 3 ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ.\n\nŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©:\n- ÿßŸÑŸÜŸàÿπ: ${carType}\n- ÿßŸÑŸÖŸàÿØŸäŸÑ: ${carModel}\n- ÿßŸÑŸÖŸÖÿ¥Ÿâ: ${mileage} ŸÉŸÖ\n${
      lastServiceType ? `- ÿ¢ÿÆÿ± ÿµŸäÿßŸÜÿ©: ${lastServiceType}` : ""
    }\n\nŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©:\n${problemDescription}\n\nÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇ:\n${historySection}\n\nŸÖÿπÿ±ŸÅ ÿßŸÑÿ¨ŸÑÿ≥ÿ©: ${
      Date.now().toString() + Math.random().toString(36).substr(2, 9)
    }\nÿßŸÑŸàŸÇÿ™: ${new Date().toISOString()}\n\nŸÖÿ∑ŸÑŸàÿ®:\n1. ÿßÿ∑ÿ±ÿ≠ 3 ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©\n2. ŸÑÿß ÿ™ŸÉÿ±ÿ± ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© - ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ¨ÿØŸäÿØÿ© ŸÖÿÆÿ™ŸÑŸÅÿ© ÿ™ŸÖÿßŸÖÿßŸã\n3. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ŸÑÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£ŸÉÿ´ÿ± ÿ™ÿ≠ÿØŸäÿØÿßŸã Ÿàÿ™ŸÅÿµŸäŸÑÿßŸã\n4. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\n5. ÿßŸÉÿ™ÿ® ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ŸÅŸÇÿ∑ÿå ÿ®ÿØŸàŸÜ ÿ£Ÿä ÿ¥ÿ±ÿ≠ ÿ•ÿ∂ÿßŸÅŸä\n6. ÿßÿ®ÿØÿ£ ŸÉŸÑ ÿ≥ÿ§ÿßŸÑ ÿ®ÿ±ŸÇŸÖ (1. 2. 3.)\n7. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ¨ÿØŸäÿØÿ© ŸÖÿÆÿµÿµÿ© ŸÑŸÑŸÖÿ¥ŸÉŸÑÿ© ŸàÿßŸÑÿ≥ŸäÿßŸÇ\n8. ÿ±ŸÉÿ≤ ÿπŸÑŸâ ÿ¨ŸàÿßŸÜÿ® ŸÖÿÆÿ™ŸÑŸÅÿ© ŸÖŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© (ÿ£ÿπÿ±ÿßÿ∂ÿå ÿ™ŸàŸÇŸäÿ™ÿå ÿ∏ÿ±ŸàŸÅÿå ÿ•ŸÑÿÆ)\n9. ÿ•ÿ∞ÿß ŸÉÿßŸÜÿ™ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿßÿ∂ÿ≠ÿ© ŸÖŸÜ ÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©ÿå ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£ŸÉÿ´ÿ± ÿ™ŸÅÿµŸäŸÑÿßŸã\n10. ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ŸáŸÜÿßŸÉ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÉÿßŸÅŸäÿ©ÿå ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ\n\nŸÖÿ´ÿßŸÑ ÿπŸÑŸâ ÿßŸÑÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®:\n1. ŸáŸÑ ŸÑÿßÿ≠ÿ∏ÿ™ ÿ£Ÿä ÿ™ÿ∫ŸäŸäÿ± ŸÅŸä ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑŸàŸÇŸàÿØÿü\n2. ŸáŸÑ ÿ™ÿ∏Ÿáÿ± ÿ£Ÿä ÿ£ÿ∂Ÿàÿßÿ° ÿ™ÿ≠ÿ∞Ÿäÿ±Ÿäÿ© ÿπŸÑŸâ ŸÑŸàÿ≠ÿ© ÿßŸÑÿπÿØÿßÿØÿßÿ™ÿü\n3. ŸáŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ™ÿ∏Ÿáÿ± ŸÅŸä ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∏ÿ±ŸàŸÅ ÿßŸÑÿ¨ŸàŸäÿ©ÿü`;
    try {
      const questionsCompletion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇ. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿØŸäŸÜÿßŸÖŸäŸÉŸäÿ© ŸàŸÖÿÆÿµÿµÿ© ŸÑŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿØÿØ.",
          },
          { role: "user", content: smartQuestionsPrompt },
        ],
        max_tokens: 400,
        temperature: 0.8,
      });
      const questionsText =
        questionsCompletion.choices[0]?.message?.content?.trim() || "";
      // Parse up to 3 unique, new questions from the response
      const questionLines = questionsText
        .split("\n")
        .filter((line) => line.trim().match(/^\d+\./));
      const followUpQuestions = questionLines
        .map((line: string, index: number) => {
          const question = line.replace(/^\d+\.\s*/, "").trim();
          return {
            id: (previousQuestions.length + index + 1).toString(),
            question: question,
            type: "text",
            timestamp: new Date().toISOString(),
          };
        })
        .filter(
          (q: { question: string }) => !previousQuestions.includes(q.question)
        )
        .slice(0, 3 - previousQuestions.length);
      if (followUpQuestions.length > 0) {
        return res.json({
          success: true,
          result: "",
          followUpQuestions,
          timestamp: new Date().toISOString(),
          note: "Smart follow-up questions generated",
        });
      } else {
        return res.json({
          success: true,
          result: "ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ•ÿ∂ÿßŸÅŸäÿ©.",
          followUpQuestions: [],
          timestamp: new Date().toISOString(),
          note: "No additional questions needed",
        });
      }
    } catch (error) {
      return res.status(500).json({
        success: false,
        message: "Failed to generate smart questions",
        error: error instanceof Error ? error.message : String(error),
      });
    }
  }

  // Step 3: Final detailed analysis
  if (currentStep === "final") {
    const historySection = buildHistorySection();
    const detailedPrompt = `\nÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÖÿ≠ÿ™ÿ±ŸÅ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸàÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©ÿå ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑŸãÿß ÿ™ŸÇŸÜŸäŸãÿß ŸÖŸÅÿµŸÑŸãÿß ŸàŸÖÿ™ŸÇÿØŸÖŸãÿß.\n\nŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©:\n- ÿßŸÑŸÜŸàÿπ: ${carType}\n- ÿßŸÑŸÖŸàÿØŸäŸÑ: ${carModel}\n- ÿßŸÑŸÖŸÖÿ¥Ÿâ: ${mileage} ŸÉŸÖ\n${
      lastServiceType ? `- ÿ¢ÿÆÿ± ÿµŸäÿßŸÜÿ©: ${lastServiceType}` : ""
    }\n${historySection}\n\nŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©:\n${problemDescription}\n\nŸÖÿ∑ŸÑŸàÿ® ŸÖŸÜŸÉ:\n1. ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿ™ŸÇŸÜŸä ŸÖŸÅÿµŸÑ ŸàŸÖÿ™ŸÇÿØŸÖ ŸÑŸÑŸÖÿ¥ŸÉŸÑÿ©\n2. ÿßÿ∞ŸÉÿ± ÿ£ÿ≥ŸÖÿßÿ° ŸÇÿ∑ÿπ ÿßŸÑÿ∫Ÿäÿßÿ± ÿßŸÑŸÖÿ≠ÿØÿØÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©\n3. ŸÇÿØŸÖ ÿ™ŸÇÿØŸäÿ±ÿßÿ™ ÿ£ÿ≥ÿπÿßÿ± ÿØŸÇŸäŸÇÿ© ÿ®ÿßŸÑÿØŸäŸÜÿßÿ± ÿßŸÑŸÉŸàŸäÿ™Ÿä (ÿØ.ŸÉ)\n4. ÿßÿ∞ŸÉÿ± ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿ•ÿµŸÑÿßÿ≠ ÿßŸÑŸÖÿ≠ÿØÿØÿ© ŸàÿßŸÑÿÆÿ∑Ÿàÿßÿ™\n5. ÿßŸÇÿ™ÿ±ÿ≠ ŸÖÿ±ÿßŸÉÿ≤ ÿµŸäÿßŸÜÿ© ŸÖŸàÿ´ŸàŸÇÿ© ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™ ŸÖÿπ ÿ£ÿ≥ŸÖÿßÿ° ŸÖÿ≠ÿØÿØÿ©\n6. ÿÆÿ∞ ŸÅŸä ÿßŸÑÿßÿπÿ™ÿ®ÿßÿ± ÿßŸÑÿ∏ÿ±ŸàŸÅ ÿßŸÑŸÖŸÜÿßÿÆŸäÿ© ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™\n7. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ\n8. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\n\nŸáÿ∞ÿß ÿ™ÿ≠ŸÑŸäŸÑ ŸÜŸáÿßÿ¶Ÿä ŸÖŸÅÿµŸÑ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖÿ™ŸàŸÅÿ±ÿ©.`;
    try {
      const completion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÖÿ≠ÿ™ÿ±ŸÅ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™ ŸÖÿπ ÿÆÿ®ÿ±ÿ© 20+ ÿ≥ŸÜÿ©. ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑÿßÿ™ ÿØŸÇŸäŸÇÿ© ŸàŸÖŸÅÿµŸÑÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿØŸäŸÜÿßÿ± ÿßŸÑŸÉŸàŸäÿ™Ÿä (ÿØ.ŸÉ) ŸÑÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿ≥ÿπÿßÿ±. ÿßÿ∞ŸÉÿ± ŸÜÿµŸäÿ≠ÿ™ŸäŸÜ ŸÅŸÇÿ∑ ŸÑŸÑŸàŸÇÿßŸäÿ©.",
          },
          { role: "user", content: detailedPrompt },
        ],
        max_tokens: 1000,
        temperature: 0.7,
      });
      const result = completion.choices[0]?.message?.content || "";
      return res.json({
        success: true,
        result: result.trim(),
        followUpQuestions: [],
        timestamp: new Date().toISOString(),
        note: "AI-generated enhanced analysis",
      });
    } catch (err) {
      return res.status(500).json({
        success: false,
        message: "AI analysis failed",
        error: err instanceof Error ? err.message : String(err),
      });
    }
  }

  // Fallback: unknown step
  return res.status(400).json({
    success: false,
    message: "Invalid step or insufficient data for analysis.",
  });
}

// Proxy /api/analyze to /api/analyze-guided for compatibility
app.post(
  "/api/analyze",
  [
    body("carType").notEmpty().withMessage("Car type is required"),
    body("carModel").notEmpty().withMessage("Car model is required"),
    body("mileage").notEmpty().withMessage("Mileage is required"),
    body("problemDescription")
      .notEmpty()
      .withMessage("Problem description is required"),
  ],
  async (req: express.Request, res: express.Response) => {
    // Validation
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({
        success: false,
        message: "Validation failed",
        errors: errors.array(),
      });
    }
    return handleAIDiagnosis(req, res);
  }
);

// Direct route for /api/analyze-guided
app.post(
  "/api/analyze-guided",
  [
    body("carType").notEmpty().withMessage("Car type is required"),
    body("carModel").notEmpty().withMessage("Car model is required"),
    body("mileage").notEmpty().withMessage("Mileage is required"),
    body("problemDescription")
      .notEmpty()
      .withMessage("Problem description is required"),
  ],
  async (req: express.Request, res: express.Response) => {
    console.log("=== /api/analyze-guided endpoint hit ===");
    // Check for validation errors
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({
        success: false,
        message: "Validation failed",
        errors: errors.array(),
      });
    }
    return handleAIDiagnosis(req, res);
  }
);

// Generate additional smart follow-up questions
app.post(
  "/api/generate-questions",
  [
    body("carDetails").notEmpty().withMessage("Car details are required"),
    body("problemDescription")
      .notEmpty()
      .withMessage("Problem description is required"),
    body("previousQuestions")
      .isArray()
      .withMessage("Previous questions must be an array"),
    body("previousAnswers")
      .isArray()
      .withMessage("Previous answers must be an array"),
    body("chatHistory")
      .optional()
      .isArray()
      .withMessage("Chat history must be an array"),
  ],
  async (req: express.Request, res: express.Response) => {
    console.log("=== /api/generate-questions endpoint hit ===");
    try {
      // Check for validation errors
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        return res.status(400).json({
          success: false,
          message: "Validation failed",
          errors: errors.array(),
        });
      }

      const {
        carDetails,
        problemDescription,
        previousQuestions,
        previousAnswers,
        chatHistory = [],
      } = req.body;

      console.log(
        "Generating additional smart questions based on previous answers"
      );

      // Check if OpenAI API key is configured
      if (!process.env.OPENAI_API_KEY) {
        return res.status(500).json({
          success: false,
          message: "OpenAI API key not configured",
          error:
            "Please configure OpenAI API key for smart questions generation",
        });
      }

      // Create dynamic prompt combining problemDescription and chatHistory
      const sessionId =
        Date.now().toString() + Math.random().toString(36).substr(2, 9);

      // Build comprehensive chat history
      let fullChatHistory = "";
      if (chatHistory.length > 0) {
        fullChatHistory = "\n\nÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑŸÉÿßŸÖŸÑ:";
        chatHistory.forEach((entry: any, index: number) => {
          fullChatHistory += `\n${index + 1}. ${entry.message || entry}`;
        });
      }

      // Build previous Q&A section
      let previousQASection = "";
      if (previousQuestions.length > 0) {
        previousQASection = "\n\nÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ŸàÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©:";
        previousQuestions.forEach((q: any, index: number) => {
          const answer = previousAnswers[index] || "(ÿ®ÿØŸàŸÜ ÿ•ÿ¨ÿßÿ®ÿ©)";
          previousQASection += `\nÿ≥ÿ§ÿßŸÑ: ${q.question || q}\nÿ•ÿ¨ÿßÿ®ÿ©: ${answer}`;
        });
      }

      const additionalQuestionsPrompt = `
ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑŸÉÿßŸÖŸÑÿå ÿßÿ∑ÿ±ÿ≠ 3 ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ.

ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©:
- ÿßŸÑŸÜŸàÿπ: ${carDetails.carType}
- ÿßŸÑŸÖŸàÿØŸäŸÑ: ${carDetails.carModel}
- ÿßŸÑŸÖŸÖÿ¥Ÿâ: ${carDetails.mileage} ŸÉŸÖ
${
  carDetails.lastServiceType ? `- ÿ¢ÿÆÿ± ÿµŸäÿßŸÜÿ©: ${carDetails.lastServiceType}` : ""
}

ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©:
${problemDescription}${fullChatHistory}${previousQASection}

ŸÖÿπÿ±ŸÅ ÿßŸÑÿ¨ŸÑÿ≥ÿ©: ${sessionId}
ÿßŸÑŸàŸÇÿ™: ${new Date().toISOString()}

ŸÖÿ∑ŸÑŸàÿ®:
1. ÿßÿ∑ÿ±ÿ≠ 3 ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©
2. ŸÑÿß ÿ™ŸÉÿ±ÿ± ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© - ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ¨ÿØŸäÿØÿ© ŸÖÿÆÿ™ŸÑŸÅÿ© ÿ™ŸÖÿßŸÖÿßŸã
3. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ŸàÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© ŸÑÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£ŸÉÿ´ÿ± ÿ™ÿ≠ÿØŸäÿØÿßŸã Ÿàÿ™ŸÅÿµŸäŸÑÿßŸã
4. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
5. ÿßŸÉÿ™ÿ® ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ŸÅŸÇÿ∑ÿå ÿ®ÿØŸàŸÜ ÿ£Ÿä ÿ¥ÿ±ÿ≠ ÿ•ÿ∂ÿßŸÅŸä
6. ÿßÿ®ÿØÿ£ ŸÉŸÑ ÿ≥ÿ§ÿßŸÑ ÿ®ÿ±ŸÇŸÖ (1. 2. 3.)
7. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ¨ÿØŸäÿØÿ© ŸÖÿÆÿµÿµÿ© ŸÑŸÑŸÖÿ¥ŸÉŸÑÿ© ŸàÿßŸÑÿ≥ŸäÿßŸÇ
8. ÿ±ŸÉÿ≤ ÿπŸÑŸâ ÿ¨ŸàÿßŸÜÿ® ŸÖÿÆÿ™ŸÑŸÅÿ© ŸÖŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© (ÿ£ÿπÿ±ÿßÿ∂ÿå ÿ™ŸàŸÇŸäÿ™ÿå ÿ∏ÿ±ŸàŸÅÿå ÿ•ŸÑÿÆ)
9. ÿ•ÿ∞ÿß ŸÉÿßŸÜÿ™ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿßÿ∂ÿ≠ÿ© ŸÖŸÜ ÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©ÿå ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£ŸÉÿ´ÿ± ÿ™ŸÅÿµŸäŸÑÿßŸã
10. ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ŸáŸÜÿßŸÉ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÉÿßŸÅŸäÿ©ÿå ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ

ŸÖÿ´ÿßŸÑ ÿπŸÑŸâ ÿßŸÑÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®:
1. ŸáŸÑ ŸÑÿßÿ≠ÿ∏ÿ™ ÿ£Ÿä ÿ™ÿ∫ŸäŸäÿ± ŸÅŸä ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑŸàŸÇŸàÿØÿü
2. ŸáŸÑ ÿ™ÿ∏Ÿáÿ± ÿ£Ÿä ÿ£ÿ∂Ÿàÿßÿ° ÿ™ÿ≠ÿ∞Ÿäÿ±Ÿäÿ© ÿπŸÑŸâ ŸÑŸàÿ≠ÿ© ÿßŸÑÿπÿØÿßÿØÿßÿ™ÿü
3. ŸáŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ™ÿ∏Ÿáÿ± ŸÅŸä ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∏ÿ±ŸàŸÅ ÿßŸÑÿ¨ŸàŸäÿ©ÿü`;

      // Generate additional questions using OpenAI
      const questionsCompletion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿßÿ∑ÿ±ÿ≠ ÿ£ÿ≥ÿ¶ŸÑÿ© ÿ∞ŸÉŸäÿ© ŸàŸÖÿ≠ÿØÿØÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ŸàÿµŸÅ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© Ÿàÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇ. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿØŸäŸÜÿßŸÖŸäŸÉŸäÿ© ŸàŸÖÿÆÿµÿµÿ© ŸÑŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿØÿØ.",
          },
          { role: "user", content: additionalQuestionsPrompt },
        ],
        max_tokens: 300,
        temperature: 0.8,
      });

      const questionsText =
        questionsCompletion.choices[0]?.message?.content || "";

      // Parse the questions from the response
      const questionLines = questionsText
        .split("\n")
        .filter((line) => line.trim().match(/^\d+\./));

      const additionalQuestions = questionLines
        .slice(0, 3)
        .map((line, index) => {
          const question = line.replace(/^\d+\.\s*/, "").trim();
          return {
            id: (previousQuestions.length + index + 1).toString(),
            question: question,
            type: "text",
            timestamp: new Date().toISOString(),
          };
        });

      console.log(
        "Generated additional smart questions:",
        additionalQuestions.map((q) => q.question)
      );

      return res.json({
        success: true,
        questions: additionalQuestions,
        timestamp: new Date().toISOString(),
        note: "AI-generated additional questions based on previous answers",
      });
    } catch (error: any) {
      console.error("Error generating additional questions:", error);
      return res.status(500).json({
        success: false,
        message: "Failed to generate additional questions",
        error: error?.message || "Unknown error",
      });
    }
  }
);

// Follow-up analysis endpoint
app.post(
  "/api/analyze-followup",
  [
    body("initialAnalysis")
      .notEmpty()
      .withMessage("Initial analysis is required"),
    body("followUpAnswers")
      .isArray()
      .withMessage("Follow-up answers must be an array"),
    body("carDetails").notEmpty().withMessage("Car details are required"),
  ],
  async (req: express.Request, res: express.Response) => {
    console.log("=== /api/analyze-followup endpoint hit ===");
    try {
      // Check for validation errors
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        return res.status(400).json({
          success: false,
          message: "Validation failed",
          errors: errors.array(),
        });
      }

      const { initialAnalysis, followUpAnswers, carDetails, image } = req.body;

      console.log("Processing follow-up analysis request");

      // Check if OpenAI API key is configured
      if (!process.env.OPENAI_API_KEY) {
        console.log(
          "[DEBUG] Fallback template response path used (no OpenAI key)"
        );

        const fallbackAnalysis = `
üöó ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÜŸáÿßÿ¶Ÿä ÿßŸÑŸÖÿ≠ÿ≥ŸÜ - ÿßŸÑŸÉŸàŸäÿ™

üìã ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©:
- ÿßŸÑŸÜŸàÿπ: ${carDetails.carType}
- ÿßŸÑŸÖŸàÿØŸäŸÑ: ${carDetails.carModel}
- ÿßŸÑŸÖŸÖÿ¥Ÿâ: ${carDetails.mileage} ŸÉŸÖ
${
  carDetails.lastServiceType ? `- ÿ¢ÿÆÿ± ÿµŸäÿßŸÜÿ©: ${carDetails.lastServiceType}` : ""
}

üîç ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©:
${carDetails.problemDescription}

‚úÖ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ£ŸàŸÑŸä:
${initialAnalysis}

üìù ÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ÿßŸÑÿ™ŸÅÿµŸäŸÑŸäÿ© ÿπŸÑŸâ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ∞ŸÉŸäÿ©:
${followUpAnswers
  .map((answer: any, index: number) => `ÿßŸÑÿ≥ÿ§ÿßŸÑ ${index + 1}: ${answer.answer}`)
  .join("\n")}

üéØ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÜŸáÿßÿ¶Ÿä ÿßŸÑŸÖÿ≠ÿ≥ŸÜ:
ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™ŸÅÿµŸäŸÑŸäÿ© ÿßŸÑŸÖŸÇÿØŸÖÿ©ÿå ŸäŸÖŸÉŸÜ ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ®ÿØŸÇÿ© ÿ£ŸÉÿ®ÿ±. 

üîß ÿßŸÑÿ™ŸàÿµŸäÿßÿ™ ÿßŸÑŸÜŸáÿßÿ¶Ÿäÿ© ŸÑŸÑŸÉŸàŸäÿ™:
1. ŸÇŸÖ ÿ®ŸÅÿ≠ÿµ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ© ŸÑÿØŸâ ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™
2. ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿµŸäÿßŸÜÿ© ÿßŸÑÿ≥Ÿäÿßÿ±ÿ© ÿßŸÑÿØŸàÿ±Ÿäÿ©
3. ÿ±ÿßŸÇÿ® ÿ£Ÿä ÿ£ÿπÿ±ÿßÿ∂ ÿ•ÿ∂ÿßŸÅŸäÿ©
4. ÿßÿ≠ÿ™ŸÅÿ∏ ÿ®ÿ≥ÿ¨ŸÑ ÿßŸÑÿµŸäÿßŸÜÿ©
5. ÿÆÿ∞ ŸÅŸä ÿßŸÑÿßÿπÿ™ÿ®ÿßÿ± ÿßŸÑÿ∏ÿ±ŸàŸÅ ÿßŸÑŸÖŸÜÿßÿÆŸäÿ© ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™

üí∞ ÿ£ÿ≥ÿπÿßÿ± ŸÇÿ∑ÿπ ÿßŸÑÿ∫Ÿäÿßÿ± ÿßŸÑŸÖÿ™ŸàŸÇÿπÿ© (ÿ®ÿßŸÑÿØŸäŸÜÿßÿ± ÿßŸÑŸÉŸàŸäÿ™Ÿä):
- ÿ≥Ÿäÿ™ŸÖ ÿ™ŸÇÿØŸäÿ± ÿßŸÑÿ£ÿ≥ÿπÿßÿ± ÿ®ÿßŸÑÿØŸäŸÜÿßÿ± ÿßŸÑŸÉŸàŸäÿ™Ÿä (ÿØ.ŸÉ) ÿ®ÿπÿØ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ™ŸÅÿµŸäŸÑŸä
- ÿßŸÑÿ£ÿ≥ÿπÿßÿ± ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ŸÜŸàÿπ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©: ${carDetails.carType} ${carDetails.carModel}

üè¢ ŸÖÿ±ÿßŸÉÿ≤ ÿßŸÑÿµŸäÿßŸÜÿ© ÿßŸÑŸÖŸÇÿ™ÿ±ÿ≠ÿ©:
- ÿ≥Ÿäÿ™ŸÖ ÿßŸÇÿ™ÿ±ÿßÿ≠ ŸÖÿ±ÿßŸÉÿ≤ ÿµŸäÿßŸÜÿ© ŸÖŸàÿ´ŸàŸÇÿ© ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™

ŸÜÿµÿßÿ¶ÿ≠ ŸÑŸÑŸàŸÇÿßŸäÿ©:
1. ŸÇŸÖ ÿ®ÿßŸÑÿµŸäÿßŸÜÿ© ÿßŸÑÿØŸàÿ±Ÿäÿ© ŸÉŸÑ 6 ÿ£ÿ¥Ÿáÿ±
2. ÿ±ÿßŸÇÿ® ŸÖÿ≥ÿ™ŸàŸâ ÿßŸÑÿ≤Ÿäÿ™ ŸàÿßŸÑŸÖÿßÿ° ÿ®ÿßŸÜÿ™ÿ∏ÿßŸÖ

‚ö†Ô∏è ŸÖŸÑÿßÿ≠ÿ∏ÿ©: Ÿáÿ∞ÿß ÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿ≠ÿ≥ŸÜ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™ŸÅÿµŸäŸÑŸäÿ©. ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ™ÿ¥ÿÆŸäÿµ ÿØŸÇŸäŸÇÿå ÿßÿ≥ÿ™ÿ¥ÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ŸÖÿ≠ÿ™ÿ±ŸÅ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™.

üîß ŸÑŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ™ŸÇÿØŸÖ: Ÿäÿ±ÿ¨Ÿâ ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸÅÿ™ÿßÿ≠ OpenAI API ŸÅŸä ŸÖŸÑŸÅ .env
        `;

        return res.json({
          success: true,
          result: fallbackAnalysis.trim(),
          timestamp: new Date().toISOString(),
          note: "Fallback response - OpenAI API key not configured",
        });
      }

      // Compose the detailed analysis prompt in Arabic with Kuwait-specific pricing
      const detailedPrompt = `
ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÖÿ≠ÿ™ÿ±ŸÅ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™. ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©ÿå ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑŸãÿß ŸÜŸáÿßÿ¶ŸäŸãÿß ŸÖŸÅÿµŸÑŸãÿß ŸàŸÖÿ™ŸÇÿØŸÖŸãÿß:

ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©:
- ÿßŸÑŸÜŸàÿπ: ${carDetails.carType}
- ÿßŸÑŸÖŸàÿØŸäŸÑ: ${carDetails.carModel}
- ÿßŸÑŸÖŸÖÿ¥Ÿâ: ${carDetails.mileage} ŸÉŸÖ
${
  carDetails.lastServiceType ? `- ÿ¢ÿÆÿ± ÿµŸäÿßŸÜÿ©: ${carDetails.lastServiceType}` : ""
}

ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©:
${carDetails.problemDescription}

ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ£ŸàŸÑŸä ÿßŸÑÿ≥ÿßÿ®ŸÇ:
${initialAnalysis}

ÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ÿßŸÑÿ™ŸÅÿµŸäŸÑŸäÿ© ÿπŸÑŸâ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ∞ŸÉŸäÿ©:
${followUpAnswers
  .map((answer: any, index: number) => `ÿßŸÑÿ≥ÿ§ÿßŸÑ ${index + 1}: ${answer.answer}`)
  .join("\n")}

${image ? "ŸÖŸÑÿßÿ≠ÿ∏ÿ©: ÿ™ŸÖ ÿ•ÿ±ŸÅÿßŸÇ ÿµŸàÿ±ÿ© ŸÑŸÑŸÖÿ¥ŸÉŸÑÿ©" : ""}

ŸÖÿ∑ŸÑŸàÿ® ŸÖŸÜŸÉ:
1. ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑ ŸÜŸáÿßÿ¶Ÿä ŸÖŸÅÿµŸÑ ŸàŸÖÿ™ŸÇÿØŸÖ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™
2. ÿßÿ∞ŸÉÿ± ÿ£ÿ≥ŸÖÿßÿ° ŸÇÿ∑ÿπ ÿßŸÑÿ∫Ÿäÿßÿ± ÿßŸÑŸÖÿ≠ÿØÿØÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©
3. ŸÇÿØŸÖ ÿ™ŸÇÿØŸäÿ±ÿßÿ™ ÿ£ÿ≥ÿπÿßÿ± ÿØŸÇŸäŸÇÿ© ÿ®ÿßŸÑÿØŸäŸÜÿßÿ± ÿßŸÑŸÉŸàŸäÿ™Ÿä (ÿØ.ŸÉ)
4. ÿßÿ∞ŸÉÿ± ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿ•ÿµŸÑÿßÿ≠ ÿßŸÑŸÖÿ≠ÿØÿØÿ© ŸàÿßŸÑÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑÿ™ŸÅÿµŸäŸÑŸäÿ©
5. ÿßŸÇÿ™ÿ±ÿ≠ ŸÖÿ±ÿßŸÉÿ≤ ÿµŸäÿßŸÜÿ© ŸÖŸàÿ´ŸàŸÇÿ© ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™ ŸÖÿπ ÿ£ÿ≥ŸÖÿßÿ° ŸÖÿ≠ÿØÿØÿ©
6. ÿÆÿ∞ ŸÅŸä ÿßŸÑÿßÿπÿ™ÿ®ÿßÿ± ÿßŸÑÿ∏ÿ±ŸàŸÅ ÿßŸÑŸÖŸÜÿßÿÆŸäÿ© ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™
7. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ
8. ŸÇÿØŸÖ ŸÜÿµÿßÿ¶ÿ≠ ŸÑŸÑŸàŸÇÿßŸäÿ© ŸÖŸÜ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑŸäÿ© (ÿßŸÇÿ™ÿµÿ± ÿπŸÑŸâ ŸÜÿµŸäÿ≠ÿ™ŸäŸÜ)
9. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©

Ÿáÿ∞ÿß ÿ™ÿ≠ŸÑŸäŸÑ ŸÜŸáÿßÿ¶Ÿä ŸÖŸÅÿµŸÑ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖÿ™ŸàŸÅÿ±ÿ© ŸàÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ÿßŸÑÿ™ŸÅÿµŸäŸÑŸäÿ©.
      `;

      console.log("Calling OpenAI API for follow-up analysis...");

      // Call OpenAI GPT
      const completion = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ŸÖŸäŸÉÿßŸÜŸäŸÉŸä ÿ≥Ÿäÿßÿ±ÿßÿ™ ŸÖÿ≠ÿ™ÿ±ŸÅ ŸÅŸä ÿßŸÑŸÉŸàŸäÿ™ ŸÖÿπ ÿÆÿ®ÿ±ÿ© 20+ ÿ≥ŸÜÿ©. ŸÇÿØŸÖ ÿ™ÿ≠ŸÑŸäŸÑÿßÿ™ ÿØŸÇŸäŸÇÿ© ŸàŸÖŸÅÿµŸÑÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿØŸäŸÜÿßÿ± ÿßŸÑŸÉŸàŸäÿ™Ÿä (ÿØ.ŸÉ) ŸÑÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿ≥ÿπÿßÿ±. ÿßÿ∞ŸÉÿ± ŸÜÿµŸäÿ≠ÿ™ŸäŸÜ ŸÅŸÇÿ∑ ŸÑŸÑŸàŸÇÿßŸäÿ©.",
          },
          { role: "user", content: detailedPrompt },
        ],
        max_tokens: 1000,
        temperature: 0.7,
      });

      const aiResponse =
        completion.choices[0]?.message?.content?.trim() ||
        "ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ™ÿ≠ŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä.";

      console.log("OpenAI API call successful for follow-up analysis");

      return res.json({
        success: true,
        result: aiResponse,
        timestamp: new Date().toISOString(),
        note: "AI-generated enhanced analysis",
      });
    } catch (error: any) {
      console.error("Error in follow-up analysis:", error);

      // Check if it's an OpenAI API error
      if (error?.response?.status === 401) {
        return res.status(500).json({
          success: false,
          message: "OpenAI API key is invalid or expired",
          error: "Please check your OpenAI API key configuration",
        });
      } else if (error?.response?.status === 429) {
        return res.status(500).json({
          success: false,
          message: "OpenAI API rate limit exceeded",
          error: "Please try again later",
        });
      } else if (
        error?.code === "ENOTFOUND" ||
        error?.code === "ECONNREFUSED"
      ) {
        return res.status(500).json({
          success: false,
          message: "Cannot connect to OpenAI API",
          error: "Please check your internet connection",
        });
      }

      return res.status(500).json({
        success: false,
        message: "Internal server error",
        error: error?.response?.data || error.message || error,
      });
    }
  }
);

// 404 handler
app.use("*", (req, res) => {
  console.log(
    `[DEBUG] 404 - Route not found: ${req.method} ${req.originalUrl}`
  );
  res.status(404).json({
    success: false,
    message: "Route not found",
  });
});

// Global error handler
app.use(
  (
    error: any,
    req: express.Request,
    res: express.Response,
    next: express.NextFunction
  ) => {
    console.error("Global error:", error);
    res.status(500).json({
      success: false,
      message: "Internal server error",
    });
  }
);

// Robust server start: try ports until one is free, never crash on EADDRINUSE
async function startServer() {
  const basePort = Number(process.env.PORT) || 8001;
  const maxAttempts = 10;
  let port = basePort;
  let attempts = 0;
  let serverStarted = false;

  while (!serverStarted && attempts < maxAttempts) {
    try {
      const server = app.listen(port, HOST, () => {
        if (port !== basePort) {
          console.log(
            `‚ö†Ô∏è  Port ${basePort} was in use. Started server on next available port: ${port}`
          );
        } else {
          console.log(`üöÄ Server running on ${HOST}:${port}`);
        }
        console.log(`üìä Health check: http://localhost:${port}/health`);
        console.log(`üîó API Base URL: http://localhost:${port}/api`);
        console.log(`üåê LAN Access: http://${HOST}:${port}`);
        console.log(
          `üéØ Target endpoint: http://192.168.8.149:${port}/api/analyze-guided`
        );
      });
      // If we get here, server started successfully
      serverStarted = true;
      process.env.PORT = port.toString();
    } catch (err: any) {
      if (err.code === "EADDRINUSE") {
        console.log(`‚ö†Ô∏è  Port ${port} in use, trying next port...`);
        port++;
        attempts++;
      } else {
        console.error("‚ùå Failed to start server:", err);
        break;
      }
    }
  }
  if (!serverStarted) {
    console.error(
      `‚ùå Could not start server on any port from ${basePort} to ${
        basePort + maxAttempts - 1
      }`
    );
  }
}

startServer();

export default app;
